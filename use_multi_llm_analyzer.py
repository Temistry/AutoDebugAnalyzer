import os
import argparse
import json
from multi_llm_analyzer import MultiLLMCodeAnalyzer
from typing import List, Dict, Any

def load_bug_report(file_path):
    """ë²„ê·¸ ë¦¬í¬íŠ¸ ë¡œë“œ í•¨ìˆ˜"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        print(f"[âš ï¸] {file_path} íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def load_source_files(source_dir):
    """ì†ŒìŠ¤ ì½”ë“œ ë¡œë“œ í•¨ìˆ˜"""
    chunks = []
    
    print(f"[ğŸ”] {source_dir} ê²½ë¡œì—ì„œ ì†ŒìŠ¤ íŒŒì¼ ìŠ¤ìº” ì¤‘...")
    
    try:
        for root, _, files in os.walk(source_dir):
            for file in files:
                if file.endswith(('.cpp', '.h')):
                    file_path = os.path.join(root, file)
                    
                    try:
                        # ANSI(CP949) ì¸ì½”ë”©ìœ¼ë¡œ íŒŒì¼ ì½ê¸° ì‹œë„
                        with open(file_path, 'r', encoding='cp949', errors='replace') as f:
                            content = f.read()
                            
                        # ì²­í¬ë¡œ ë¶„í•  (100ì¤„ ë‹¨ìœ„)
                        lines = content.split('\n')
                        chunk_size = 100
                        
                        for i in range(0, len(lines), chunk_size):
                            end_idx = min(i + chunk_size, len(lines))
                            chunk_content = '\n'.join(lines[i:end_idx])
                            
                            if chunk_content.strip():  # ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ë§Œ
                                chunks.append({
                                    'file_path': file_path,
                                    'start_line': i + 1,
                                    'end_line': end_idx,
                                    'content': chunk_content
                                })
                                
                    except UnicodeDecodeError:
                        # CP949 ì‹¤íŒ¨ ì‹œ EUC-KRë¡œ ì‹œë„
                        try:
                            with open(file_path, 'r', encoding='euc-kr', errors='replace') as f:
                                content = f.read()
                                
                            # ê°™ì€ ì²­í¬ ë¶„í•  ë¡œì§ ë°˜ë³µ
                            lines = content.split('\n')
                            for i in range(0, len(lines), chunk_size):
                                end_idx = min(i + chunk_size, len(lines))
                                chunk_content = '\n'.join(lines[i:end_idx])
                                
                                if chunk_content.strip():
                                    chunks.append({
                                        'file_path': file_path,
                                        'start_line': i + 1,
                                        'end_line': end_idx,
                                        'content': chunk_content
                                    })
                        except Exception as e2:
                            print(f"[âš ï¸] {file_path} íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e2}")
                    
                    except Exception as e:
                        print(f"[âš ï¸] {file_path} íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                        
        print(f"[âœ…] {len(chunks)}ê°œ ì½”ë“œ ì²­í¬ ìƒì„± ì™„ë£Œ")
        return chunks
        
    except Exception as e:
        print(f"[âŒ] ì†ŒìŠ¤ íŒŒì¼ ìŠ¤ìº” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ëª…ë ¹ì¤„ ì¸ì íŒŒì‹±
    parser = argparse.ArgumentParser(description='ë‹¤ì¤‘ LLM ê¸°ë°˜ ì½”ë“œ ë¶„ì„ ë„êµ¬')
    parser.add_argument('--bug_report', type=str, default="D:/data/GersangDebugAutomation/bug_report.txt",
                        help='ë²„ê·¸ ë¦¬í¬íŠ¸ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--source_dir', type=str, default="C:/data/Branch_Trunk_bugfix",
                        help='ì†ŒìŠ¤ ì½”ë“œ ë””ë ‰í† ë¦¬ ê²½ë¡œ')
    parser.add_argument('--knowledge', type=str, default="dev_knowledge.txt",
                        help='ê°œë°œì ì§€ì‹ íŒŒì¼ ê²½ë¡œ (ì—†ìœ¼ë©´ ê¸°ë³¸ ë¶„ì„ ì§„í–‰)')
    parser.add_argument('--script_dir', type=str, default="C:/data/GCS",
                        help='ê²Œì„ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ë””ë ‰í† ë¦¬ ê²½ë¡œ')
    
    # ë²ˆì—­ê¸° LLM ì„¤ì •
    parser.add_argument('--translator_url', type=str, default="http://192.168.102.166:1234",
                        help='ë²ˆì—­ê¸° LLM API ì„œë²„ ì£¼ì†Œ')
    parser.add_argument('--translator_model', type=str, default="eeve-korean-instruct-10.8b-v1.0",
                        help='ë²ˆì—­ê¸° LLM ëª¨ë¸ ì´ë¦„')
    
    # ì½”ë“œ ë¶„ì„ LLM ì„¤ì •ì„ ìœ„í•œ ì¸ìë“¤
    parser.add_argument('--code_llms', type=str, nargs='+', default=[],
                        help='ì½”ë“œ ë¶„ì„ LLM ì •ë³´ (í˜•ì‹: ì´ë¦„:ì£¼ì†Œ:ëª¨ë¸ëª…:ì „ë¬¸ë¶„ì•¼, ì˜ˆ: qwen:http://localhost:1234:Qwen2.5-7B:code)')
    parser.add_argument('--config', type=str, default="config.json",
                        help='LLM ì„¤ì • íŒŒì¼ ê²½ë¡œ')
    
    args = parser.parse_args()
    
    # config.json íŒŒì¼ ë¡œë“œ ì‹œë„
    config = {}
    if os.path.exists(args.config):
        try:
            with open(args.config, 'r', encoding='utf-8') as f:
                config = json.load(f)
            print(f"[âœ…] ì„¤ì • íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {args.config}")
        except Exception as e:
            print(f"[âš ï¸] ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    else:
        print(f"[â„¹ï¸] ì„¤ì • íŒŒì¼({args.config})ì´ ì—†ìŠµë‹ˆë‹¤. ëª…ë ¹ì¤„ ì¸ìë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    # ê²½ë¡œ ì„¤ì • (config ê°’ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ëª…ë ¹ì¤„ ì¸ì ì‚¬ìš©)
    if config and 'defaults' in config:
        defaults = config['defaults']
        bug_report_path = args.bug_report or defaults.get('bug_report_path')
        source_dir = args.source_dir or defaults.get('source_dir')
        knowledge_file = (args.knowledge if os.path.exists(args.knowledge) else defaults.get('knowledge_file')) if os.path.exists(args.knowledge) else None
        script_dir = (args.script_dir if os.path.exists(args.script_dir) else defaults.get('script_dir')) if os.path.exists(args.script_dir) else None
    else:
        bug_report_path = args.bug_report
        source_dir = args.source_dir
        knowledge_file = args.knowledge if os.path.exists(args.knowledge) else None
        script_dir = args.script_dir if os.path.exists(args.script_dir) else None
    
    # 1. ë‹¤ì¤‘ LLM ë¶„ì„ê¸° ì´ˆê¸°í™”
    print("\n[ğŸ¤–] ë‹¤ì¤‘ LLM ì½”ë“œ ë¶„ì„ê¸° ì´ˆê¸°í™” ì¤‘...")
    
    # ë²ˆì—­ê¸° ì„¤ì • (config ê°’ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ëª…ë ¹ì¤„ ì¸ì ì‚¬ìš©)
    translator_url = args.translator_url
    translator_model = args.translator_model
    
    if config and 'llm_servers' in config and 'translator' in config['llm_servers']:
        translator_config = config['llm_servers']['translator']
        translator_url = translator_config.get('url', translator_url)
        translator_model = translator_config.get('model', translator_model)
    
    analyzer = MultiLLMCodeAnalyzer(
        translator_url=translator_url,
        translator_model=translator_model,
        knowledge_file=knowledge_file,
        script_dir=script_dir
    )
    
    # 2. ì½”ë“œ ë¶„ì„ LLM ë“±ë¡
    code_llms_registered = False
    
    # config.jsonì—ì„œ LLM ë“±ë¡
    if config and 'llm_servers' in config and 'code_analyzers' in config['llm_servers']:
        code_analyzers = config['llm_servers']['code_analyzers']
        if code_analyzers:
            for llm_config in code_analyzers:
                try:
                    name = llm_config.get('name')
                    url = llm_config.get('url')
                    model = llm_config.get('model')
                    specialty = llm_config.get('specialty', 'general')
                    description = llm_config.get('description', '')
                    
                    if name and url and model:
                        print(f"[ğŸ”„] ì„¤ì • íŒŒì¼ì—ì„œ ì½”ë“œ ë¶„ì„ LLM ë“±ë¡ ì¤‘: {name} ({description})")
                        analyzer.add_code_llm(name, url, model, specialty)
                        code_llms_registered = True
                    else:
                        print(f"[âš ï¸] ì„¤ì • íŒŒì¼ì˜ LLM ì •ë³´ê°€ ë¶ˆì™„ì „í•©ë‹ˆë‹¤: {llm_config}")
                except Exception as e:
                    print(f"[âš ï¸] ì„¤ì • íŒŒì¼ì˜ LLM ë“±ë¡ ì¤‘ ì˜¤ë¥˜: {e}")
    
    # ëª…ë ¹ì¤„ ì¸ìì—ì„œ LLM ë“±ë¡ (config.jsonì—ì„œ ë“±ë¡í•œ ê²ƒì´ ì—†ì„ ë•Œë§Œ)
    if not code_llms_registered and args.code_llms:
        for llm_info in args.code_llms:
            try:
                parts = llm_info.split(':')
                if len(parts) >= 3:
                    name = parts[0]
                    url = parts[1]
                    model = parts[2]
                    specialty = parts[3] if len(parts) > 3 else "general"
                    
                    print(f"[ğŸ”„] ëª…ë ¹ì¤„ ì¸ìì—ì„œ ì½”ë“œ ë¶„ì„ LLM ë“±ë¡ ì¤‘: {name} ({url}, {model})")
                    analyzer.add_code_llm(name, url, model, specialty)
                    code_llms_registered = True
                else:
                    print(f"[âš ï¸] ì˜ëª»ëœ LLM ì •ë³´ í˜•ì‹: {llm_info}")
            except Exception as e:
                print(f"[âŒ] LLM ë“±ë¡ ì¤‘ ì˜¤ë¥˜: {e}")
    
    # ê¸°ë³¸ ì½”ë“œ LLMì´ ì—†ìœ¼ë©´ í•˜ë‚˜ ì¶”ê°€
    if not code_llms_registered:
        print("[â„¹ï¸] ì½”ë“œ ë¶„ì„ LLMì´ ì§€ì •ë˜ì§€ ì•Šì•„ ê¸°ë³¸ LLM ì‚¬ìš©")
        default_url = "http://localhost:1234"
        default_model = "Qwen2.5-Coder-7B-Instruct-Uncensored"
        analyzer.add_code_llm("default-coder", default_url, default_model, "code")
    
    # 3. ë²„ê·¸ ë¦¬í¬íŠ¸ ë¡œë“œ
    print(f"\n[ğŸ“„] ë²„ê·¸ ë¦¬í¬íŠ¸ ë¡œë“œ ì¤‘: {bug_report_path}")
    bug_report = load_bug_report(bug_report_path)
    if not bug_report:
        print("[âŒ] ë²„ê·¸ ë¦¬í¬íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # 4. ë²„ê·¸ ë¦¬í¬íŠ¸ ë¶„ì„
    print("\n[ğŸ”] ë²„ê·¸ ë¦¬í¬íŠ¸ ë¶„ì„ ì¤‘...")
    bug_analysis = analyzer.analyze_bug_report(bug_report)
    
    # 5. ì†ŒìŠ¤ ì½”ë“œ ë¡œë“œ
    print("\n[ğŸ“‚] ì†ŒìŠ¤ ì½”ë“œ ë¡œë“œ ì¤‘...")
    code_chunks = load_source_files(source_dir)
    if not code_chunks:
        print("[âŒ] ì†ŒìŠ¤ ì½”ë“œ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # 6. ì½”ë“œ ë¬¸ë§¥ ë§¤ì¹­
    print("\n[ğŸ”„] ì½”ë“œ ë¬¸ë§¥ ë¶„ì„ ì¤‘...")
    matching_chunks = analyzer.match_with_code_context(bug_report, bug_analysis, code_chunks, top_n=5)
    
    # ë§¤ì¹­ëœ ì½”ë“œê°€ ì—†ëŠ” ê²½ìš°
    if not matching_chunks:
        print("[âš ï¸] ë²„ê·¸ì™€ ê´€ë ¨ëœ ì½”ë“œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        print("\n[âœ…] ë¶„ì„ ì™„ë£Œ")
        return
    
    # 7. ê²°ê³¼ ì¶œë ¥
    print("\n[ğŸ“Š] === ë¶„ì„ ê²°ê³¼ ===")
    print(f"ë²„ê·¸ ìœ í˜•: {bug_analysis.get('bug_type', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
    print(f"ì‹¬ê°ë„: {bug_analysis.get('severity', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
    print(f"ë²„ê·¸ ìš”ì•½: {bug_analysis.get('summary', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
    print(f"ê´€ë ¨ í‚¤ì›Œë“œ: {', '.join(bug_analysis.get('keywords', ['ì—†ìŒ']))}")
    
    print("\n[ğŸ”] ì˜ì‹¬ ì½”ë“œ ì˜ì—­:")
    for i, chunk in enumerate(matching_chunks, 1):
        # file_path í‚¤ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ file í‚¤ ì‚¬ìš©
        file_path = chunk.get('file_path', chunk.get('file', 'ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼'))
        # ìƒëŒ€ ê²½ë¡œë§Œ ìˆëŠ” ê²½ìš° ì „ì²´ ê²½ë¡œ ìƒì„±
        if '/' not in file_path and '\\' not in file_path and os.path.exists(os.path.join(source_dir, file_path)):
            file_path = os.path.join(source_dir, file_path)
            
        file_name = os.path.basename(file_path)
        
        print(f"\n{i}. íŒŒì¼: {file_name}")
        print(f"   ì „ì²´ ê²½ë¡œ: {file_path}")
        print(f"   ì½”ë“œ ìœ„ì¹˜: {chunk.get('start_line', 0)}~{chunk.get('end_line', 0)} ë¼ì¸")
        
        # ì˜ì‹¬ ë¼ì¸ ì •ë³´ ì¶œë ¥
        suspected_lines = chunk.get('suspected_lines', [])
        if suspected_lines:
            print(f"   ì˜ì‹¬ ë¼ì¸: {', '.join(map(str, suspected_lines))}")
            
            # ì°¸ì¡°ëœ ì½”ë“œ ì¶œë ¥
            referenced_code = chunk.get('referenced_code', [])
            if referenced_code:
                print("\n   ì°¸ì¡°ëœ ì½”ë“œ:")
                for ref in referenced_code:
                    line_num = ref.get('line', '?')
                    code = ref.get('code', 'ì½”ë“œ ì •ë³´ ì—†ìŒ')
                    reason = ref.get('reason', '')
                    print(f"   {line_num}ë²ˆ ì¤„: {code}")
                    if reason:
                        print(f"      â†³ ì´ìœ : {reason}")
        
        # ë¶„ì„ ì‹ ë¢°ë„ í‘œì‹œ
        confidence = chunk.get('confidence', 'ì•Œ ìˆ˜ ì—†ìŒ')
        print(f"   ë¶„ì„ ì‹ ë¢°ë„: {confidence}")
        print(f"   ê´€ë ¨ì„± ì ìˆ˜: {chunk.get('relevance_score', 0)}/10")
        print(f"   ë¶„ì„: {chunk.get('reasoning', 'ì •ë³´ ì—†ìŒ')}")
    
    # 8. ìµœìƒìœ„ ë§¤ì¹­ì— ëŒ€í•œ ìˆ˜ì • ì œì•ˆ ìƒì„±
    if matching_chunks:
        print("\n[ğŸ’¡] ìˆ˜ì • ì œì•ˆ ìƒì„± ì¤‘...")
        # ì²« ë²ˆì§¸ ë§¤ì¹­ì—ì„œ file_path í‚¤ í™•ì¸
        top_match = matching_chunks[0]
        if 'file_path' not in top_match and 'file' in top_match:
            # file_path í‚¤ê°€ ì—†ê³  file í‚¤ê°€ ìˆìœ¼ë©´ file_path í‚¤ ì¶”ê°€
            top_match['file_path'] = top_match['file']
            
        fix_suggestion = analyzer.generate_fix_suggestion(bug_report, top_match)
        print("\n[ğŸ› ï¸] ìˆ˜ì • ì œì•ˆ:")
        print(fix_suggestion)
    
    print("\n[âœ…] ë¶„ì„ ì™„ë£Œ")

if __name__ == "__main__":
    main() 